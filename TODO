----- STREAM OF CONSCIOUSNESS TODO FILE --------------------------------
The contents of this file may not make sense to anyone (including me).
Proceed at your own peril.
------------------------------------------------------------------------


O. add multiprocessing.RLock to blacklist database calls
    O. remove database/* locks
O. instead of communicating with messages through a queue,
    just pass self.blacklist & have messages make blacklist calls
O. refactor Reddit instantiation
    O. move to reddit.py (maybe rename redditprefix -> reddit)
    O. refactor bot.py:_handle_rate_limit -> reddit.py
        O. create a generic error handler which calls the pertinent
          error-handler (map APIException handlers by error_type)
        O. need to notify all processes of rate-limit & put all to sleep
    O. instantiate in bot.__init__
    O. instantiate another instance in messages.run_forever
O. add config options:
    O. SEND_DEBUG_PM on/off
        O. refactor into separate class? (in replies.py maybe?)
            -- needs to instantiate its own Reddit instance (to get the
            redditor object)
        ? add more debug pms
4? move messages.py reply methods to replies.py .. maybe
    I don't think anything else should need those specific methods
    (but the same can probably said of the methods in replies.py)
O. mentions parsing
    O. queue.put( thing.submission )
    O. gate by time -- don't parse through the same submission within
        T time
          but there could be new comments with usable links
          someone could spam mentions in a single submission
            eg. hitting enter a bunch of times because of lag
        O. maybe keep a database of (username, submission) & only
            queue.put if the specific combination has not been seen
            (prevents the same user summoning multiple times)
O. refactor messages, mentions stream parsing to mixin/base class
    O. change ProcessBase -> ProcessMixin
    O. handle prawcore.exceptions.RequestException (internet hiccup, etc)
O. implement bot.subs
    O. read subreddits from database / json
    O. join subreddits with '+'
    O. update from database whenever the file mtime changes
        (this is required for mentions-added subreddits to work without
         bot restart)
O. refactor database to use context-management (with statements) & commit/rollback
O. instagram stuff
    O. fetching & caching (+config option to expire cache)
        O. parse data into usable format
        O. caching = save data to file .. maybe a database? json?
            O. sqlite3 caching = check against file mtime
    O. bad links db for temp bans (404s only?)
        => if #bad_links > THRESHOLD: temp ban user!
    O. if ig fetch was triggered by mentions (submission_queue)
        and ig fetch was successful (fetch ok or cached)
        then add subreddit to to-add db:
            if subreddit reaches a threshold of successful mention summons
            then add subreddit to subreddit.comment stream parsing (bot.py)
O. instagram rate-limit queue
    O. needs database (ig_user, comment.fullname, last_id*, timestamp**)
      *last_id may be null if rate-limited before any fetches were made
        otherwise this should be the last fetched id (data['items'][-1]['id'])
      **timestamp could also just be an INTEGER AUTOINCREMENT
        O. how to treat table as queue?
            > SELECT ... FROM ... ORDER BY timestamp ASC;
    O. instagram inserts on rate-limit + other?
    O. bot processes every so often? alternatively, instagram processes queue
      whenever under rate-limit (needs a way to call appropriate bot reply
      func tho... or could instantiate a Reddit instance i guess..)
        O. refactor instagram.__*rate_limit* methods to public staticmethods
          so that bot.py can see them & use them to process queue
        O. whatever handles consuming queue needs to handle that ig_user hitting
          rate-limit again:
            > UPDATE ... (last_id)
        O. on successful fetch:
            > DELETE ...
8? catch-up (parse through old (all?) messages maybe comments/mentions)
    in case the bot is offline for a while, this would catch messages to be
    processed
    - refactor messages to fetch until first not-seen message
        (I think stream_generator only fetches the first 100 then continually
         tries to fetch the newest)
    ? refactor mentions/comments similarly
        this behavior may not be desirable; could end up responding to weeks-old
        comments to be seen by no one
9. commandline arguments
    . --config-path
    . --add-subreddit
    . --rm-subreddit
    . --add-blacklist
    . --rm-blacklist
    . --lookup-*
        database lookups; not sure which atm .. maybe all?
10? delay comment replies with persistent queue
    it seems like some people dislike bots because they reply with information
    that is useless to them. delaying the reply could potentially mitigate some
    hate.
11. don't dynamically add subreddits if they are blacklisted
12. instagram requests user-agent
13. versioning
N-1. refactor logging
    - add pid (+ option to disable)

N. testing!

